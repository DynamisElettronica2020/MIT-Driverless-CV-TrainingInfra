{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitfb145c69a41e49ec9393ba0ede4656b6",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Train Your Own Cone Detection and Key Points Detection Networks\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70957091-fe06a480-2042-11ea-8c06-0fcc549fc19a.png)\n",
    "\n",
    "In this notebook, we will demonstrate \n",
    "- how to train your own YOLOv3-based traffic cone detection network and do inference on a video.\n",
    "- how to train your own KeyPoints detection network and do inference on pictures of traffic cone.\n",
    "\n",
    "**[Accurate Low Latency Visual Perception for Autonomous Racing: Challenges Mechanisms and Practical Solutions](https://github.com/mit-han-lab/once-for-all)** is an accurate low latency visual perception system introduced by Kieran Strobel, Sibo Zhu, Raphael Chang, and Skanda Koppula.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70950893-e2de6980-202f-11ea-9a16-399579926ee5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Preparation\n",
    "Let's first install all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\n\nunzip is already the newest version (6.0-21ubuntu1).\nThe following packages were automatically installed and are no longer required:\n  cuda-10-1 cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\n  cuda-gdb-10-1 cuda-gpu-library-advisor-10-1 cuda-libraries-10-1\n  cuda-libraries-dev-10-1 cuda-license-10-1 cuda-memcheck-10-1\n  cuda-misc-headers-10-1 cuda-npp-10-1 cuda-npp-dev-10-1 cuda-nsight-10-1\n  cuda-nsight-compute-10-1 cuda-nsight-systems-10-1 cuda-nvcc-10-1\n  cuda-nvdisasm-10-1 cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n  cuda-nvjpeg-dev-10-1 cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1\n  cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1\n  cuda-runtime-10-1 cuda-samples-10-1 cuda-sanitizer-api-10-1\n  cuda-toolkit-10-1 cuda-tools-10-1 cuda-visual-tools-10-1 grub-pc-bin\n  libnvidia-common-418 libnvidia-common-430\nUse 'sudo apt autoremove' to remove them.\n0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\nInstalling PyTorch...\nCollecting torch\n  Using cached https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl\nCollecting future (from torch)\nCollecting numpy (from torch)\n  Using cached https://files.pythonhosted.org/packages/22/e7/4b2bdddb99f5f631d8c1de259897c2b7d65dcfcc1e0a6fd17a7f62923500/numpy-1.19.1-cp36-cp36m-manylinux1_x86_64.whl\nInstalling collected packages: future, numpy, torch\nSuccessfully installed future-0.18.2 numpy-1.19.1 torch-1.6.0\nInstalling torchvision...\nCollecting torchvision\n  Using cached https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl\nCollecting numpy (from torchvision)\n  Using cached https://files.pythonhosted.org/packages/22/e7/4b2bdddb99f5f631d8c1de259897c2b7d65dcfcc1e0a6fd17a7f62923500/numpy-1.19.1-cp36-cp36m-manylinux1_x86_64.whl\nCollecting pillow>=4.1.1 (from torchvision)\n  Using cached https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl\nCollecting torch==1.6.0 (from torchvision)\n  Using cached https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl\n"
    }
   ],
   "source": [
    "! sudo apt install unzip\n",
    "print('Installing PyTorch...')\n",
    "! pip3 install torch \n",
    "print('Installing torchvision...')\n",
    "! pip3 install torchvision \n",
    "print('Installing numpy...')\n",
    "! pip3 install numpy \n",
    "# tqdm is a package for displaying a progress bar.\n",
    "print('Installing tqdm (progress bar) ...')\n",
    "! pip3 install tqdm \n",
    "print('Installing matplotlib...')\n",
    "! pip3 install matplotlib \n",
    "print('Installing all the other required packages once for all')\n",
    "! sudo python3 setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Before we start training, let's download the Cone Detection dataset and the corresponding label and intial training weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading Training Dataset\")\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/YOLO_Dataset.zip\n",
    "! unzip YOLO_Dataset.zip\n",
    "! mv YOLO_Dataset dataset/ && rm YOLO_Dataset.zip\n",
    "print(\"Downloading YOLOv3 Sample Weights\")\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/sample-yolov3.weights \n",
    "print(\"Downloading Training and Validation Label\")\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/all.csv && cd ..\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/train.csv && cd ..\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/validate.csv && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Using Pretrained YOLOv3 Weights File to Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First, import all the packages used in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import time\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import math\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import Darknet\n",
    "from utils.datasets import ImageLabelDataset\n",
    "from utils.utils import model_info, print_args, Logger, visualize_and_save_to_local,xywh2xyxy\n",
    "import validate\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "##### section for all random seeds #####\n",
    "torch.manual_seed(17)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "########################################\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "num_cpu = multiprocessing.cpu_count() if cuda else 0\n",
    "if cuda:\n",
    "    torch.cuda.synchronize()\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Successfully imported all packages and configured random seed to 17!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(label_prefix, data_loader, num_steps, optimizer, model, epoch, num_epochs, step):\n",
    "    print(f\"Model in {label_prefix} mode\")\n",
    "    epoch_losses = [0.0] * 7\n",
    "    epoch_time_total = 0.0\n",
    "    epoch_num_targets = 1e-12\n",
    "    t1 = time.time()\n",
    "    loss_labels = [\"Total\", \"L-x\", \"L-y\", \"L-w\", \"L-h\", \"L-noobj\", \"L-obj\"]\n",
    "    for i, (img_uri, imgs, targets) in enumerate(data_loader):\n",
    "        if step[0] >= num_steps:\n",
    "            break\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        targets.requires_grad_(False)\n",
    "        step_num_targets = ((targets[:, :, 1:5] > 0).sum(dim=2) > 1).sum().item() + 1e-12\n",
    "        epoch_num_targets += step_num_targets\n",
    "        # Compute loss, compute gradient, update parameters\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        losses = model(imgs, targets)\n",
    "        if label_prefix == \"train\":\n",
    "            losses[0].sum().backward()\n",
    "        if optimizer is not None:\n",
    "            optimizer.step()\n",
    "\n",
    "        for j, (label, loss) in enumerate(zip(loss_labels, losses)):\n",
    "            batch_loss = loss.sum().to('cpu').item()\n",
    "            epoch_losses[j] += batch_loss\n",
    "        finished_time = time.time()\n",
    "        step_time_total = finished_time - t1\n",
    "        epoch_time_total += step_time_total\n",
    "        \n",
    "        statement = label_prefix + ' Epoch: ' + str(epoch) + ', Batch: ' + str(i + 1) + '/' + str(len(data_loader))\n",
    "        count = 0\n",
    "        for (loss_label, loss) in zip(loss_labels, losses):\n",
    "            if count == 0:\n",
    "                statement += ', Total: ' + '{0:10.6f}'.format(loss.item() / step_num_targets)\n",
    "                tot_loss = loss.item()\n",
    "                count += 1\n",
    "            else:\n",
    "                statement += ',   ' + loss_label + ': {0:5.2f}'.format(loss.item() / tot_loss * 100) + '%'\n",
    "        print(statement)\n",
    "        if label_prefix == \"train\":\n",
    "            step[0] += 1\n",
    "    return epoch_losses, epoch_time_total, epoch_num_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = False\n",
    "batch_size = int(5)\n",
    "optimizer_pick = \"Adam\"\n",
    "model_cfg = \"model_cfg/yolo_baseline.cfg\"\n",
    "weights_path = \"sample-yolov3.weights\"\n",
    "output_path = \"automatic\"\n",
    "dataset_path = \"dataset/YOLO_Dataset/\"\n",
    "num_epochs = int(2048)\n",
    "num_steps = 8388608\n",
    "checkpoint_interval = int(1)\n",
    "augment_affine = False\n",
    "augment_hsv = False\n",
    "lr_flip = False\n",
    "ud_flip = False\n",
    "momentum = float(0.9)\n",
    "gamma = float(0.95)\n",
    "lr = float(0.001)\n",
    "weight_decay = float(0.0)\n",
    "vis_batch = int(0)\n",
    "data_aug = False\n",
    "blur = False\n",
    "salt = False\n",
    "noise = False\n",
    "contrast = False\n",
    "sharpen = False\n",
    "ts = True\n",
    "debug_mode = False\n",
    "upload_dataset = False\n",
    "xy_loss = float(2)\n",
    "wh_loss= float(1.6)\n",
    "no_object_loss = float(25)\n",
    "object_loss = float(0.1)\n",
    "vanilla_anchor = False\n",
    "val_tolerance = int(3)\n",
    "min_epochs = int(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arguments = list(locals().items())\n",
    "\n",
    "print(\"Initializing model\")\n",
    "model = Darknet(config_path=model_cfg,xy_loss=xy_loss,wh_loss=wh_loss,no_object_loss=no_object_loss,object_loss=object_loss,vanilla_anchor=vanilla_anchor)\n",
    "img_width, img_height = model.img_size()\n",
    "bw  = model.get_bw()\n",
    "validate_uri, train_uri = model.get_links()\n",
    "\n",
    "if output_path == \"automatic\":\n",
    "    current_month = datetime.now().strftime('%B').lower()\n",
    "    current_year = str(datetime.now().year)\n",
    "    if not os.path.exists(os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1])):\n",
    "        os.makedirs(os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1]))\n",
    "    output_uri = os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1])\n",
    "else:\n",
    "    output_uri = output_path\n",
    "\n",
    "num_validate_images, num_train_images = model.num_images()\n",
    "conf_thresh, nms_thresh, iou_thresh = model.get_threshs()\n",
    "num_classes = model.get_num_classes()\n",
    "loss_constant = model.get_loss_constant()\n",
    "conv_activation = model.get_conv_activation()\n",
    "anchors = model.get_anchors()\n",
    "onnx_name = model.get_onnx_name()\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tensorboard_data_dir:\n",
    "    print(\"Initializing data loaders\")\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        ImageLabelDataset(train_uri, dataset_path=dataset_path, width=img_width, height=img_height, augment_hsv=augment_hsv,\n",
    "                            augment_affine=augment_affine, num_images=num_train_images,\n",
    "                            bw=bw, n_cpu=num_cpu, lr_flip=lr_flip, ud_flip=ud_flip,vis_batch=vis_batch,data_aug=data_aug,blur=blur,salt=salt,noise=noise,contrast=contrast,sharpen=sharpen,ts=ts,debug_mode=debug_mode, upload_dataset=upload_dataset),\n",
    "        batch_size=(1 if debug_mode else batch_size),\n",
    "        shuffle=(False if debug_mode else True),\n",
    "        num_workers=(0 if vis_batch else num_cpu),\n",
    "        pin_memory=cuda)\n",
    "    print(\"Num train images: \", len(train_data_loader.dataset))\n",
    "\n",
    "    validate_data_loader = torch.utils.data.DataLoader(\n",
    "        ImageLabelDataset(validate_uri, dataset_path=dataset_path, width=img_width, height=img_height, augment_hsv=False,\n",
    "                            augment_affine=False, num_images=num_validate_images,\n",
    "                            bw=bw, n_cpu=num_cpu, lr_flip=False, ud_flip=False,vis_batch=vis_batch,data_aug=False,blur=False,salt=False,noise=False,contrast=False,sharpen=False,ts=ts,debug_mode=debug_mode, upload_dataset=upload_dataset),\n",
    "        batch_size=(1 if debug_mode else batch_size),\n",
    "        shuffle=False,\n",
    "        num_workers=(0 if vis_batch else num_cpu),\n",
    "        pin_memory=cuda)\n",
    "    print(\"Num validate images: \", len(validate_data_loader.dataset))\n",
    "\n",
    "    ##### additional configuration #####\n",
    "    print(\"Training batch size: \" + str(batch_size))\n",
    "    \n",
    "    print(\"Checkpoint interval: \" + str(checkpoint_interval))\n",
    "\n",
    "    print(\"Loss constants: \" + str(loss_constant))\n",
    "\n",
    "    print(\"Anchor boxes: \" + str(anchors))\n",
    "\n",
    "    print(\"Training image width: \" + str(img_width))\n",
    "\n",
    "    print(\"Training image height: \" + str(img_height))\n",
    "\n",
    "    print(\"Confidence Threshold: \" + str(conf_thresh))\n",
    "\n",
    "    print(\"Number of training classes: \" + str(num_classes))\n",
    "\n",
    "    print(\"Conv activation type: \" + str(conv_activation))\n",
    "\n",
    "    print(\"Starting learning rate: \" + str(lr))\n",
    "\n",
    "    if ts:\n",
    "        print(\"Tile and scale mode [on]\")\n",
    "    else:\n",
    "        print(\"Tile and scale mode [off]\")\n",
    "\n",
    "    if data_aug:\n",
    "        print(\"Data augmentation mode [on]\")\n",
    "    else:\n",
    "        print(\"Data augmentation mode [off]\")\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    weights_path = weights_path\n",
    "    if optimizer_pick == \"Adam\":\n",
    "        print(\"Using Adam Optimizer\")\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                    lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_pick == \"SGD\":\n",
    "        print(\"Using SGD Optimizer\")\n",
    "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(f\"Invalid optimizer name: {optimizer_pick}\")\n",
    "    print(\"Loading weights\")\n",
    "    model.load_weights(weights_path, model.get_start_weight_dim())\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print('Using ', torch.cuda.device_count(), ' GPUs')\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device, non_blocking=True)\n",
    "\n",
    "    # Set scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    val_loss = 999  # using a high number for validation loss\n",
    "    val_loss_counter = 0\n",
    "    step = [0]  # wrapping in an array so it is mutable\n",
    "    epoch = start_epoch\n",
    "    while epoch < num_epochs and step[0] < num_steps and not evaluate:\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        run_epoch(label_prefix=\"train\", data_loader=train_data_loader, epoch=epoch,\n",
    "                    step=step, model=model, num_epochs=num_epochs, num_steps=num_steps,\n",
    "                    optimizer=optimizer)\n",
    "        print('Completed epoch: ', epoch)\n",
    "        # Update best loss\n",
    "        if epoch % checkpoint_interval == 0 or epoch == num_epochs or step[0] >= num_steps:\n",
    "            # First, save the weights\n",
    "            save_weights_uri = os.path.join(output_uri, \"{epoch}.weights\".format(epoch=epoch))\n",
    "            model.save_weights(save_weights_uri)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                print(\"Calculating loss on validate data\")\n",
    "                epoch_losses, epoch_time_total, epoch_num_targets = run_epoch(\n",
    "                    label_prefix=\"validate\", data_loader=validate_data_loader, epoch=epoch,\n",
    "                    model=model, num_epochs=num_epochs, num_steps=num_steps, optimizer=None,\n",
    "                    step=step)\n",
    "                avg_epoch_loss = epoch_losses[0] / epoch_num_targets\n",
    "                print('Average Validation Loss: {0:10.6f}'.format(avg_epoch_loss))\n",
    "\n",
    "                if avg_epoch_loss > val_loss and epoch > min_epochs:\n",
    "                    val_loss_counter += 1\n",
    "                    print(f\"Validation loss did not decrease for {val_loss_counter}\"\n",
    "                            f\" consecutive check(s)\")\n",
    "                else:\n",
    "                    print(\"Validation loss decreased. Yay!!\")\n",
    "                    val_loss_counter = 0\n",
    "                    val_loss = avg_epoch_loss\n",
    "                    ##### updating best result for optuna study #####\n",
    "                    result = open(\"logs/result.txt\", \"w\" )\n",
    "                    result.write(str(avg_epoch_loss))\n",
    "                    result.close() \n",
    "                    ###########################################\n",
    "                validate.validate(dataloader=validate_data_loader, model=model, device=device, step=step[0], bbox_all=False,debug_mode=debug_mode)\n",
    "                if val_loss_counter == val_tolerance:\n",
    "                    print(\"Validation loss stopped decreasing over the last \" + str(val_tolerance) + \" checkpoints, creating onnx file\")\n",
    "                    with tempfile.NamedTemporaryFile() as tmpfile:\n",
    "                        model.save_weights(tmpfile.name)\n",
    "                        weights_name = tmpfile.name\n",
    "                        cfg_name = os.path.join(tempfile.gettempdir(), model_cfg.split('/')[-1].split('.')[0] + '.tmp')\n",
    "                        onnx_gen = subprocess.call(['python3', 'yolo2onnx.py', '--cfg_name', cfg_name, '--weights_name', weights_name])\n",
    "                        save_weights_uri = os.path.join(output_uri, onnx_name)\n",
    "                        os.rename(weights_name, save_weights_uri)\n",
    "                        try:\n",
    "                            os.remove(onnx_name)\n",
    "                        except:\n",
    "                            pass\n",
    "                        os.remove(cfg_name)\n",
    "                    break\n",
    "    if evaluate:\n",
    "        validation = validate.validate(dataloader=validate_data_loader, model=model, device=device, step=-1, bbox_all=False, tensorboard_writer=None,debug_mode=debug_mode)\n",
    "return val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  }
 ]
}