{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitfb145c69a41e49ec9393ba0ede4656b6",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Train Your Own Cone Detection and Key Points Detection Networks\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70957091-fe06a480-2042-11ea-8c06-0fcc549fc19a.png)\n",
    "\n",
    "In this notebook, we will demonstrate \n",
    "- how to train your own YOLOv3-based traffic cone detection network and do inference on a video.\n",
    "- how to train your own KeyPoints detection network and do inference on pictures of traffic cone.\n",
    "\n",
    "**[Accurate Low Latency Visual Perception for Autonomous Racing: Challenges Mechanisms and Practical Solutions](https://github.com/mit-han-lab/once-for-all)** is an accurate low latency visual perception system introduced by Kieran Strobel, Sibo Zhu, Raphael Chang, and Skanda Koppula.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70950893-e2de6980-202f-11ea-9a16-399579926ee5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Preparation\n",
    "Let's first install all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\n\nunzip is already the newest version (6.0-21ubuntu1).\nThe following packages were automatically installed and are no longer required:\n  cuda-10-1 cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\n  cuda-gdb-10-1 cuda-gpu-library-advisor-10-1 cuda-libraries-10-1\n  cuda-libraries-dev-10-1 cuda-license-10-1 cuda-memcheck-10-1\n  cuda-misc-headers-10-1 cuda-npp-10-1 cuda-npp-dev-10-1 cuda-nsight-10-1\n  cuda-nsight-compute-10-1 cuda-nsight-systems-10-1 cuda-nvcc-10-1\n  cuda-nvdisasm-10-1 cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1\n  cuda-nvjpeg-dev-10-1 cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1\n  cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1\n  cuda-runtime-10-1 cuda-samples-10-1 cuda-sanitizer-api-10-1\n  cuda-toolkit-10-1 cuda-tools-10-1 cuda-visual-tools-10-1 grub-pc-bin\n  libnvidia-common-418 libnvidia-common-430\nUse 'sudo apt autoremove' to remove them.\n0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\nCollecting imgaug\n  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n\u001b[K    100% |████████████████████████████████| 952kB 1.3MB/s \n\u001b[?25hCollecting matplotlib (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/96/a7/b6fa244fd8a8814ef9408c8a5a7e4ed0340e232a6f0ce2046b42e50672c0/matplotlib-3.3.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n\u001b[K    100% |████████████████████████████████| 11.6MB 119kB/s \n\u001b[?25hCollecting Shapely (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/9d/18/557d4f55453fe00f59807b111cc7b39ce53594e13ada88e16738fb4ff7fb/Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n\u001b[K    100% |████████████████████████████████| 1.0MB 1.3MB/s \n\u001b[?25hCollecting scipy (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/2b/a8/f4c66eb529bb252d50e83dbf2909c6502e2f857550f22571ed8556f62d95/scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n\u001b[K    100% |████████████████████████████████| 25.9MB 48kB/s \n\u001b[?25hCollecting Pillow (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n\u001b[K    100% |████████████████████████████████| 2.2MB 645kB/s \n\u001b[?25hCollecting numpy>=1.15 (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/22/e7/4b2bdddb99f5f631d8c1de259897c2b7d65dcfcc1e0a6fd17a7f62923500/numpy-1.19.1-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n\u001b[K    100% |████████████████████████████████| 13.4MB 102kB/s \n\u001b[?25hCollecting scikit-image>=0.14.2 (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n\u001b[K    100% |████████████████████████████████| 12.4MB 107kB/s \n\u001b[?25hCollecting six (from imgaug)\n  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\nCollecting opencv-python (from imgaug)\n  Downloading https://files.pythonhosted.org/packages/77/f5/49f034f8d109efcf9b7e98fbc051878b83b2f02a1c73f92bbd37f317288e/opencv-python-4.4.0.42.tar.gz (88.9MB)\n\u001b[K    100% |████████████████████████████████| 88.9MB 13kB/s \n\u001b[?25h    Complete output from command python setup.py egg_info:\n    Traceback (most recent call last):\n      File \"<string>\", line 1, in <module>\n      File \"/tmp/pip-build-helqzb4c/opencv-python/setup.py\", line 9, in <module>\n        import skbuild\n    ModuleNotFoundError: No module named 'skbuild'\n    \n    ----------------------------------------\n\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-helqzb4c/opencv-python/\u001b[0m\n"
    }
   ],
   "source": [
    "! sudo apt install unzip\n",
    "! pip3 install imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, let's build the Cone Detection dataset and the corresponding dataloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "aset/vid_28_frame_1099.jpg  \n  inflating: YOLO_Dataset/vid_209_frame_101.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2312.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1714.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_45511.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1050.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_842.jpg  \n  inflating: YOLO_Dataset/vid_78_frame_192.jpg  \n  inflating: YOLO_Dataset/vid_216_frame_159.jpg  \n  inflating: YOLO_Dataset/vid_108_frame_351.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3052.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_426.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2290.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_35752.jpg  \n  inflating: YOLO_Dataset/vid_123_frame_8624.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_317.jpg\n  inflating: YOLO_Dataset/vid_38_frame_629.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2374.jpg  \n  inflating: YOLO_Dataset/vid_205_frame_26.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1595.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_662.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_461.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_13264.jpg  \n  inflating: YOLO_Dataset/vid_67_frame_144.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2758.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_184.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1750.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_2208.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1991.jpg  \n  inflating: YOLO_Dataset/vid_77_frame_4.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1408.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_83.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1220.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1890.jpg  \n  inflating: YOLO_Dataset/vid_83_frame_223.jpg  \n  inflating: YOLO_Dataset/vid_105_frame_98.jpg  \n  inflating: YOLO_Dataset/vid_112_frame_54.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_752.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_400.jpg\n  inflating: YOLO_Dataset/vid_42_frame_278.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_710.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1118.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_197.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3051.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3138.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2022.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_10209.jpg  \n  inflating: YOLO_Dataset/vid_97_frame_199.jpg  \n  inflating: YOLO_Dataset/vid_89_frame_46.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_840.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_786.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3065.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2111.jpg  \n  inflating: YOLO_Dataset/vid_50_frame_356.jpg  \n  inflating: YOLO_Dataset/vid_112_frame_13.jpg  \n  inflating: YOLO_Dataset/vid_97_frame_35.jpg  \n  inflating: YOLO_Dataset/vid_108_frame_691.jpg  \n  inflating: YOLO_Dataset/vid_73_frame_59.jpg  \n  inflating: YOLO_Dataset/vid_71_frame_165.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2446.jpg  \n  inflating: YOLO_Dataset/vid_65_frame_22.jpg  \n  inflating: YOLO_Dataset/vid_225_frame_231.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3234.jpg\n  inflating: YOLO_Dataset/vid_88_frame_343.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_742.jpg  \n  inflating: YOLO_Dataset/vid_228_frame_29.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1813.jpg  \n  inflating: YOLO_Dataset/vid_92_frame_38.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1785.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_659.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2905.jpg  \n  inflating: YOLO_Dataset/vid_96_frame_59.jpg  \n  inflating: YOLO_Dataset/vid_63_frame_4.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1769.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1123.jpg  \n  inflating: YOLO_Dataset/vid_75_frame_232.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1763.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1296.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1254.jpg  \n  inflating: YOLO_Dataset/vid_70_frame_81.jpg  \n  inflating: YOLO_Dataset/vid_77_frame_181.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_104.jpg  \n  inflating: YOLO_Dataset/vid_221_frame_6.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_655.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1465.jpg  \n  inflating: YOLO_Dataset/vid_88_frame_185.jpg  \n  inflating: YOLO_Dataset/vid_75_frame_305.jpg  \n  inflating: YOLO_Dataset/vid_78_frame_256.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_36322.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1685.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1593.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_402.jpg\n  inflating: YOLO_Dataset/vid_3_frame_18065.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2716.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_224.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2140.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_557.jpg  \n  inflating: YOLO_Dataset/vid_213_frame_203.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1210.jpg  \n  inflating: YOLO_Dataset/vid_57_frame_138.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_3643.jpg  \n  inflating: YOLO_Dataset/vid_51_frame_41.jpg  \n  inflating: YOLO_Dataset/vid_202_frame_33.jpg  \n  inflating: YOLO_Dataset/vid_89_frame_206.jpg  \n  inflating: YOLO_Dataset/vid_65_frame_138.jpg  \n  inflating: YOLO_Dataset/vid_108_frame_174.jpg  \n  inflating: YOLO_Dataset/vid_77_frame_330.jpg  \n  inflating: YOLO_Dataset/vid_76_frame_366.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_904.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1789.jpg  \n  inflating: YOLO_Dataset/vid_6_frame_2663.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1638.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2489.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_791.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2707.jpg  \n  inflating: YOLO_Dataset/vid_75_frame_303.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_507.jpg\n  inflating: YOLO_Dataset/vid_2_frame_18292.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2032.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2519.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_300.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1500.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_803.jpg  \n  inflating: YOLO_Dataset/vid_97_frame_16.jpg  \n  inflating: YOLO_Dataset/vid_98_frame_30.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2007.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1886.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_715.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_305.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1067.jpg  \n  inflating: YOLO_Dataset/vid_213_frame_182.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_363.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2472.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2319.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2370.jpg  \n  inflating: YOLO_Dataset/vid_76_frame_130.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_78.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_2062.jpg  \n  inflating: YOLO_Dataset/vid_101_frame_145.jpg  \n  inflating: YOLO_Dataset/vid_104_frame_142.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_791.jpg\n  inflating: YOLO_Dataset/vid_105_frame_94.jpg  \n  inflating: YOLO_Dataset/vid_36_frame_348.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1210.jpg  \n  inflating: YOLO_Dataset/vid_215_frame_92.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2570.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2256.jpg  \n  inflating: YOLO_Dataset/vid_90_frame_179.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_850.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_101.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1708.jpg  \n  inflating: YOLO_Dataset/vid_77_frame_302.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1243.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_2135.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2443.jpg  \n  inflating: YOLO_Dataset/vid_202_frame_5.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1995.jpg  \n  inflating: YOLO_Dataset/vid_210_frame_54.jpg  \n  inflating: YOLO_Dataset/vid_123_frame_5078.jpg  \n  inflating: YOLO_Dataset/vid_95_frame_18.jpg  \n  inflating: YOLO_Dataset/vid_50_frame_397.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_397.jpg  \n  inflating: YOLO_Dataset/vid_6_frame_8340.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_2142.jpg  \n  inflating: YOLO_Dataset/vid_93_frame_93.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1797.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2900.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_275.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1249.jpg  \n  inflating: YOLO_Dataset/vid_124_frame_1291.jpg\n  inflating: YOLO_Dataset/vid_18_frame_2095.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_44943.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_304.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1635.jpg  \n  inflating: YOLO_Dataset/vid_73_frame_145.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1803.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_890.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_944.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1804.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2337.jpg  \n  inflating: YOLO_Dataset/vid_76_frame_89.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_462.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_14434.jpg  \n  inflating: YOLO_Dataset/vid_76_frame_426.jpg  \n  inflating: YOLO_Dataset/vid_6_frame_5552.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1237.jpg  \n  inflating: YOLO_Dataset/vid_79_frame_99.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_2111.jpg  \n  inflating: YOLO_Dataset/vid_6_frame_34689.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1707.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2149.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_34736.jpg  \n  inflating: YOLO_Dataset/vid_109_frame_331.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_919.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_836.jpg\n  inflating: YOLO_Dataset/vid_40_frame_1047.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3075.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1399.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1721.jpg  \n  inflating: YOLO_Dataset/vid_36_frame_210.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3206.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_1004.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2663.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1305.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1986.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_5110.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_294.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_253.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1935.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1113.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1678.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_306.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_946.jpg\n  inflating: YOLO_Dataset/vid_225_frame_29.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_42673.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_2477.jpg  \n  inflating: YOLO_Dataset/vid_122_frame_5153.jpg  \n  inflating: YOLO_Dataset/vid_62_frame_60.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_88.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_2605.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_45.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_163.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_256.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_24616.jpg  \n  inflating: YOLO_Dataset/vid_105_frame_100.jpg  \n  inflating: YOLO_Dataset/vid_36_frame_472.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1948.jpg  \n  inflating: YOLO_Dataset/vid_94_frame_213.jpg  \n  inflating: YOLO_Dataset/vid_74_frame_164.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1651.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2088.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1882.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_2094.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_20107.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1898.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2201.jpg  \n  inflating: YOLO_Dataset/vid_121_frame_12066.jpg  \n  inflating: YOLO_Dataset/vid_124_frame_3689.jpg  \n  inflating: YOLO_Dataset/vid_109_frame_14.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_668.jpg\n  inflating: YOLO_Dataset/vid_38_frame_856.jpg  \n  inflating: YOLO_Dataset/vid_59_frame_141.jpg  \n  inflating: YOLO_Dataset/vid_3_frame_25413.jpg  \n  inflating: YOLO_Dataset/vid_62_frame_170.jpg  \n  inflating: YOLO_Dataset/vid_112_frame_258.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2311.jpg  \n  inflating: YOLO_Dataset/vid_73_frame_213.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2017.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2157.jpg  \n  inflating: YOLO_Dataset/vid_71_frame_86.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_26305.jpg  \n  inflating: YOLO_Dataset/vid_124_frame_5217.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1862.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1333.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1387.jpg  \n  inflating: YOLO_Dataset/vid_50_frame_37.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_821.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_804.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1920.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1988.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2951.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_512.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2423.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1011.jpg\n  inflating: YOLO_Dataset/vid_3_frame_27419.jpg  \n  inflating: YOLO_Dataset/vid_6_frame_15158.jpg  \n  inflating: YOLO_Dataset/vid_72_frame_180.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2224.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_37193.jpg  \n  inflating: YOLO_Dataset/vid_99_frame_47.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1506.jpg  \n  inflating: YOLO_Dataset/vid_67_frame_54.jpg  \n  inflating: YOLO_Dataset/vid_108_frame_126.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_327.jpg  \n  inflating: YOLO_Dataset/vid_41_frame_489.jpg  \n  inflating: YOLO_Dataset/vid_89_frame_196.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2118.jpg  \n  inflating: YOLO_Dataset/vid_68_frame_23.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_33499.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2224.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2228.jpg  \n  inflating: YOLO_Dataset/vid_89_frame_131.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2475.jpg  \n  inflating: YOLO_Dataset/vid_98_frame_51.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2071.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_853.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_760.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_2250.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1879.jpg  \n  inflating: YOLO_Dataset/vid_200_frame_130.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_469.jpg\n  inflating: YOLO_Dataset/vid_2_frame_34618.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1680.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_718.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2647.jpg  \n  inflating: YOLO_Dataset/vid_36_frame_137.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2998.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_537.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1273.jpg  \n  inflating: YOLO_Dataset/vid_121_frame_11249.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2330.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1170.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1382.jpg  \n  inflating: YOLO_Dataset/vid_121_frame_9975.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_671.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_39667.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1620.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_3055.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2941.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1332.jpg  \n  inflating: YOLO_Dataset/vid_206_frame_48.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1206.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_817.jpg\n  inflating: YOLO_Dataset/vid_201_frame_20.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2659.jpg  \n  inflating: YOLO_Dataset/vid_78_frame_122.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_74.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_2454.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_176.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1789.jpg  \n  inflating: YOLO_Dataset/vid_71_frame_355.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1898.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_164.jpg  \n  inflating: YOLO_Dataset/vid_50_frame_393.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_887.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_2317.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2729.jpg  \n  inflating: YOLO_Dataset/vid_36_frame_173.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_167.jpg  \n  inflating: YOLO_Dataset/vid_28_frame_1477.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1900.jpg  \n  inflating: YOLO_Dataset/vid_64_frame_675.jpg  \n  inflating: YOLO_Dataset/vid_2_frame_36769.jpg  \n  inflating: YOLO_Dataset/vid_37_frame_367.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_422.jpg\n  inflating: YOLO_Dataset/vid_30_frame_1596.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2740.jpg  \n  inflating: YOLO_Dataset/vid_84_frame_2.jpg  \n  inflating: YOLO_Dataset/vid_42_frame_325.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2179.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1716.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1353.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_1105.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_1719.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1628.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2531.jpg  \n  inflating: YOLO_Dataset/vid_207_frame_123.jpg  \n  inflating: YOLO_Dataset/vid_225_frame_248.jpg  \n  inflating: YOLO_Dataset/vid_101_frame_164.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1183.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_56.jpg  \n  inflating: YOLO_Dataset/vid_231_frame_43.jpg  \n  inflating: YOLO_Dataset/vid_40_frame_115.jpg  \n  inflating: YOLO_Dataset/vid_88_frame_431.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_86.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2129.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2188.jpg  \n  inflating: YOLO_Dataset/vid_38_frame_529.jpg\n  inflating: YOLO_Dataset/vid_5_frame_2043.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2142.jpg  \n  inflating: YOLO_Dataset/vid_31_frame_2560.jpg  \n  inflating: YOLO_Dataset/vid_5_frame_1267.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1657.jpg  \n  inflating: YOLO_Dataset/vid_50_frame_176.jpg  \n  inflating: YOLO_Dataset/vid_83_frame_62.jpg  \n  inflating: YOLO_Dataset/vid_101_frame_79.jpg  \n  inflating: YOLO_Dataset/vid_18_frame_1464.jpg  \n  inflating: YOLO_Dataset/vid_30_frame_1556.jpg  \n  inflating: YOLO_Dataset/vid_45_frame_720.jpg  \n  inflating: YOLO_Dataset/vid_227_frame_171.jpg  \n--2020-08-25 00:45:47--  https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/all.csv\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 108.177.120.128, 108.177.111.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\nHTTP request sent, awaiting response...200 OK\nLength: 2483612 (2.4M) [application/octet-stream]\nSaving to: ‘all.csv’\n\nall.csv             100%[===================>]   2.37M  --.-KB/s    in 0.02s   \n\n2020-08-25 00:45:48 (98.1 MB/s) - ‘all.csv’ saved [2483612/2483612]\n\n--2020-08-25 00:45:48--  https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/train.csv\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 108.177.120.128, 108.177.111.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\nHTTP request sent, awaiting response...200 OK\nLength: 1861466 (1.8M) [application/octet-stream]\nSaving to: ‘train.csv’\n\ntrain.csv           100%[===================>]   1.77M  --.-KB/s    in 0.01s   \n\n2020-08-25 00:45:48 (156 MB/s) - ‘train.csv’ saved [1861466/1861466]\n\n--2020-08-25 00:45:49--  https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/validate.csv\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 108.177.120.128, 108.177.111.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\nHTTP request sent, awaiting response...200 OK\nLength: 358746 (350K) [application/octet-stream]\nSaving to: ‘validate.csv’\n\nvalidate.csv        100%[===================>] 350.34K  --.-KB/s    in 0.003s  \n\n2020-08-25 00:45:49 (110 MB/s) - ‘validate.csv’ saved [358746/358746]\n\n"
    }
   ],
   "source": [
    "print(\"Downloading Training Dataset\")\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/YOLO_Dataset.zip\n",
    "! unzip YOLO_Dataset.zip\n",
    "! mv YOLO_Dataset CVC-YOLOv3/dataset/ && cd CVC-YOLOv3/dataset/\n",
    "! cd CVC-YOLOv3/dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/all.csv && cd ../..\n",
    "! cd CVC-YOLOv3/dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/train.csv && cd ../..\n",
    "! cd CVC-YOLOv3/dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/validate.csv && cd ../..\n",
    "! rm YOLO_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}